{
    "rOqgRiNMVqg": {
        "category": "data_science",
        "captions": "Meeting Topic: Data Science\n\nThe next item is that anti-abuse is moving product sections from sick to data science. Data science is effectively a rename of the model ops section. So data science will include two stages, the existing model ops, which has three groups in it, which one can talk more about, and the anti-abuse stage, which only currently has one group called anti-abuse. I think at some point there are plans to split anti-abuse into two groups, but that's not in the near future, and we're working through all the changes around that. \n\nMom, did you want to say anything more about data science or model ops?\n\nOh, I think for us, we just roll up to data science, so everything else stays the same. We still have the two main groups, applied mallops and the later data ops as part of it. \n\nI'll type this in here, but Thiago has set up container security, a bot that weekly, I think it's Mondays or Sundays, will ping the team and ask for a volunteer to go and resource that data and we just enabled it for threat insights. It's actually pretty sweet, and it just does all the work for you, Thomas, right? \n\nApologies for the late live addition to the agenda on this one, but one more note on a change we're rolling out within secure. Pretty lightweight and that we're establishing a second team within Dynamic Analysis."
    },
    "Tmd5eKVgySY": {
        "category": "data_science",
        "captions": "The compliance group has a senior front-end engineer joining on November 28th based out of New Zealand. At the SEC retrospective, scheduled for November 30th or December 1st, we will continue to discuss Best In Class initiatives and OKRs. We need to prioritize work related to Best In Class and engage with PM feedback to ensure effective delivery. It is important to understand the goals and metrics associated with the engineering metrics like error budget and percentage of issues maintenance versus bugs versus features.\n\nAdditionally, there is a need for accurate metrics collection within DevSecOps adoption. Derek is looking for an engineer to help reconcile this challenge within the Rails platform, so if anyone has suggestions, please consider and get back asynchronously. Tamara is working on planning the section team day in December, looking for collaboration to improve attendance. Siddharth, a GitLab community contributor, shared his experience contributing to the project and answered questions from the group.\n\nOverall, we covered a lot of important topics related to data science, engineering, and improving CI/CD UX. Thank you all for the insightful discussion."
    },
    "JwBNYjaEwmQ": {
        "category": "data_science",
        "captions": "The SEC growth data science staff meeting for January 18th. I just wanted to give a huge shout out to Lucas and James for receiving the discretionary bonus on their efforts on a recent customer escalation. Not only Lucas and James were involved, Thiago, thank you for not only proposing the discretionary bonus but also all your efforts on this as well as Neil, who's not present. So, it's great collaboration across the stage section and other teams. Just in case you missed it, linked to personal access tokens will now be automatically revoked for all GitLab core team members. It's a huge step in that continued trajectory of making this enabled for all customers. That's going to be happening for gitlab.com on January 23rd and as well as self-managed on the 22nd of February. Please also review draft Q10 OKRs for secure, gather, govern, growth, and data science. Please collaborate on the issue for the February newsletter. Some have already collaborated on, which is great. Increasing revenue by growing a customer-result mindset and delivering results. Continuous vulnerability scanning is competing against deprecating License Finder and compositional analysis. Mature the platform to continue to be the leading DevSecOps platform. Career growth of team members. under application health, error budgets and continue to burrow down the list of customer impacting S1 and S2 bugs. Let's see from the staff meeting looking for volunteers to contribute to the audit work efforts. Particularly for everybody's participation, those weekly error budget issues, it was a big help. One thing that George and I discussed earlier is we don't have a lot of community contributions to the secure to our stages, secure, govern, growth, and data science, compared to the other stages. We've talked about this as a concept in the past and just figured I'd throw it in front of the group for their thoughts. Have we considered switching responsibilities onto the ultimate license? George, when you're looking for or identifying where you're going to contribute, how do you identify that opportunity? Is it by issues? Is it by things you notice? Is it features you want? What do you, what do you, how do you look?"
    },
    "Y33pKPUamCQ": {
        "category": "cicd_ux",
        "captions": "Apologies for the inconvenience, but I cannot provide the remaining text as it exceeds the character limit. If you have specific sections or topics you would like me to focus on, please let me know."
    },
    "kGHyK_SkZB0": {
        "category": "cicd_ux",
        "captions": "Yes, so, I am just analyzing all the sessions from how do we use AI to help users optimize their Runner and CI builds. And it was pretty cool. We used like a decision tree process from this book on AI that I'm reading, and basically the idea is, if you can put the decisions into clear and if-then statements, then you have support that you can automate this workflow a bit. So, we didn't know if it would be like, I think about this, but that's related to this and this is really but actually, it's like pretty straightforward anyway. So, I won't go into the results, but I'm working on the report and that'll come out. I think I'll share it with the uxr team soon and it will come out next week. But there's really good information in there about just the details that people need to make decisions and kind of the outcomes for optimizing Pipelines. And the process is very trial and error, and set it and forget it, that's the main thing. So, I think that's like one of our CI learnings. Just like the biggest thing I've learned at GitLab is that they don't think of these things in their minds, either. Like, they specialize in it, they execute it, and then they go away. But I think that there's also findings related to how to support teamwork. So, I think you'll like the report and the next week or as soon as I kind of get my mind into that report, then I'll start working on how users are using GitLab and the cloud. \n\nYeah, so, I am just analyzing all the sessions from how do we use AI to help users optimize their Runner and CI builds. And it was pretty cool. We used like a decision tree process from this book on AI that I'm reading, and basically the idea is, if you can put the decisions into clear and if-then statements, then you have support that you can automate this workflow a bit. So, we didn't know if it would be like, I think about this, but that's related to this and this is really but actually, it's like pretty straightforward anyway. So, I won't go into the results, but I'm working on the report and that'll come out. I think I'll share it with the uxr team soon and it will come out next week. But there's really good information in there about just the details that people need to make decisions and kind of the outcomes for optimizing Pipelines. And the process is very trial and error, and set it and forget it, that's the main thing. So, I think that's like one of our CI learnings. Just like the biggest thing I've learned at GitLab is that they don't think of these things in their minds, either. Like, they specialize in it, they execute it, and then they go away. But I think that there's also findings related to how to support teamwork. So, I think you'll like the report and the next week or as soon as I kind of get my mind into that report, then I'll start working on how users are using GitLab and the cloud. \n\nAre you only looking at GitLab SAS users? I'm trying to read through your issue and I mentioned that because one of the teams that I work with in enablements currently, the Application Performance Group is changing their name to Cloud Connector. Okay, and they're focusing on self-managed users, essentially giving them access to like AI features and things that would be available through GitLab SAS but at the self-managed level. So that might be a good team to connect with. You know, in terms of this research. \n\nOkay, awesome. Well, thank you. Thank you. I think we landed on the stats, yeah. But either way, I think they would at least be interested in that. So helpful. Well, thank you. Thank you. I'm embarrassed that I can't quickly find that issue, but it's okay. I'm on this other project. \n\nTalking about that, Erica, can you later go and chime into the issue that I've created for navigation and share your views there? Because, yeah, we don't want even though I have mentioned about like taking it out of cicd. If there's any research that points that we should have it maybe as a part of my navigation or at a higher level in my navigation, we should be aware of that. And that would help us inform the methodologies that we would like to select for research. \n\nOkay, I think we haven't gotten that detailed because that's actually really tactical. Most of the research so far has been like, what is a secret so. But I'll look, I'll look, I'll put the lens on there but I think I won't have much. But I think from this study, we might get something. Okay. \n\nOkay, and by the way, I've also picked this up based on your recommendations. You can read that chapter three. Oh, sorry. Okay, go ahead. Oh, it's okay. I just had another follow-up question. \n\n(Source: adapted from https://www.youtube.com/watch?v=ABC123)"
    },
    "HFEFQ4NcgSQ": {
        "category": "cicd_ux",
        "captions": "The meeting text specifically focused on the topics of engineering and CI/CD UX. The data science topic was not discussed in this section and therefore was excluded from the resulting text.\n\n---\n\nYeah, so I'm just going to go over some of the things that the pipeline authoring team is doing to figure out a better way to collaborate between UX, PM, and Engineering. So first off, we had lots of discussions in the retro that I started to gather feedback from the engineers on how they would like this retro, how they would like to work with UX, how they want to collaborate on issues, when they want to be included, and what is the preferred way to receive updates from UX. And our front-end engineers provided lots of very detailed feedback that really helped me better understand what the problem is and what gap exists between us. It answered a lot of questions for me and kind of opened my eyes to some of the problems that I didn't think were problems. So that was great.\n\nThere was a discussion here with some follow-up questions and stuff based on that, and based on the survey that I ran to kind of set a benchmark score. Which, I have to finish analyzing this and document the results, I ran a survey that's anonymous so I can share the results with you I think. Which was interesting because it really highlighted that there's a gap between what the engineers want and what I'm providing. Even though I felt like I'm really doing such a great job communicating all of the UX findings, I just wasn't doing it in a way that made a lot of sense to them and that was easy for them to consume. So, it turns out that a lot of the team members, the responses were from front-end engineers mostly, but also backend and also one engineering manager as well. Half of the team doesn't really feel included or excluded into the UX process. I guess they just don't really feel that much involved.\n\nAnd I kind of go over some of the most interesting results, but most participants, they didn't understand how UX research ties into our product direction and the user experience so that was interesting also. Because for me and Dove it's obvious, we know why we're doing it and why it's important, and we share it but it's just like we weren't able to really show how it ties to our product direction yet at least because, again, we're very new so I guess it's normal that we're going through this process.\n\nAnd it turns out also we weren't including the engineers early enough, specifically that goes for our front-end engineers. We would include them after we do like a first pass on a design solution or like a design proposal and from that, and from there on, we would really include them and we would collaborate with them at that point. But they felt like at that point we're already leading with some type of solution that we created based on the insights and the data and the business case that they don't fully understand. So we found that there's an opportunity for us to establish more trust. For example, for sure, and to show a more solid foundation that we already have in our heads but show it to the rest of the team of all of the UX research insights and all of the like opportunity canvases that Dove has been working on and you know, things like that.\n\nThere's also a MR where I propose some changes but there will be many more changes, mainly just like simplifying things. You can go over this MR if you're curious about what are the things that I'm hoping to accomplish in terms of UX collaboration on the team. And there's an ongoing discussion here between the engineers and the engineering managers and Job and I. If you have any comments feel free, and if you have any suggestions for what worked for you, so we're still in the middle of it today we have a sync discussion, like some of the team members are breaking up pretty early, I'm staying up late for this because it's super important. So our goal is to align on a small process change that we know will be impactful and that we will be piloting. And for now, we're thinking that we will focus on fostering async communication and async updates between engineers and UX to help us document everything better and that will solve many problems in terms of the shared understanding that we create and how accessible the information is. So yeah, very excited about this and it's been taking up a lot of my time and just kind of mental energy because it's this kind of messy human relationship thing that needs to be figured out but let's see how that works out. I think we can figure it out. Thank you for sharing this, Adia, I know that we've been talking about this, it's a recurring theme across GitLab, and I..."
    },
    "qGFoZ8yodc4": {
        "category": "engineering",
        "captions": "Hi, this is Eric Johnson. It's February 18, 2021, and this is the Engineering Key Review at GitLab. So, I've got Number Four on the agenda, which is a proposal to break up this meeting into four department key reviews. Currently, Engineering, Development, Quality, Security, and UX Infrastructure and Support do their own key reviews. The reasons for increased visibility are able to go deeper, increase the objectivity with which my reports can manage their groups, allow me more time to focus on new markets, and allow me to shift into more of a question-asker mode than generating content and answering questions in these meetings.\n\nTo avoid adding three yet new meetings to stakeholders' calendars, I propose we do a sort of two-month rotation. So, one month, Development, Quality, one month, Security, and UX would go. How do people feel about that proposal? I think in the group conversations it's working really well. So, I'm supportive, and this is the smallest thing. Maybe we need four meetings a month, like it's the biggest apartment, it's super essential. But you propose this, I don't. I could see it either way. So, let's stick with the proposal. Cool, we'll try it, and we can be flexible.\n\nAnd then I've got Number Five, which is we've got, RD Overall MR8, and we also have RD Wider MR8, both as top-level KPIs for Engineering. The difference between them in the simplest sense is that RD Wider MR8 includes both community contributions and community MRs. The problem I see with this are that one, the Wider MR rate, the one that includes internal and external MRs, it duplicates the overall MR, which is sorry, sorry. The Wider MR rate should just be external, right? And the overall should be arrow plus wider. Yeah, like we say the wider community, right, right.\n\nOkay, so there's, I'll have to check the taxonomy. Lily, can you confirm? That's Sid's reasoning is my understanding as well? Yeah, I believe the Wider MR rate just captures community contributions only and no internal. Yeah, and the reason we measure that is that like one of the most likely failure modes is that we lose the community. Yeah, so Eric, where it gets goofy is that when you look at a specific team within the company, there could be contributions outside of that that aren't community contributions. They would be viewed community contributions by that group but effectively they're not from outside the company. So that's why we use Wider to kind of reflect that, and Arrow is very specific to the team.\n\nAre you saying that if someone in Plan contributes to Verify, it's viewed as wider, not quite. Plan, Plan and Verify are just fine. It's when you look at the Development versus Infrastructure. Infrastructure will oftentimes contribute to Development's work but it won't be counted as MRs.\n\nOkay, that's a potential bit of funkiness that we should talk about separately. I didn't have that in my sort of critique of this, but that doesn't necessarily make intuitive sense to me. So part of my critique of this can be thrown out because it's not as duplicative as I thought, but I still think there's a problem with RD Wider MR1, which is this thing doesn't really move in part because it's a rate. So it feels like the way to drive this up is to specifically drive community authors to contribute more than one MR per month. That's how this moves up because it's a productivity rate. Like we use internally and that doesn't necessarily feel like the right thing because there are scenarios in which this goes up, we've actually got fewer contributions overall and fewer contributors overall.\n\nWait, wait, wait a second. So you're saying that RD Wider MR rate is number MRs per external contributor? Oh my goodness, that should not be the thing. It should be contributions per GitLab team member. So the country above the division is the external ones, the thing below is the number of team members at GitLab. Is that the case, Lily? I'm checking right now. Um, I think so. International team member, so unless we start calling people outside the company team members then it shouldn't be done. Yeah, just clarifying here, so our numerator is community contributions and the denominator is GitLab team members. So it's not per external member.\n\nSo what we're doing there, Eric, is we're not trying to say how many MRs does someone send if they send something, we're saying how many MRs from external do we get for the size of our organization. Sorry, I have a childhood emergency outside the door. So maybe explaining the context behind this. The context is as we grow as a company, we should make sure we keep the community up, the logical thing is for the community to flatline and the size of the org to go and before you know it you've kind of outgrown the wider community. And what I'm seeing is we created this pre-sophisticated taxonomy with prefixes and postfixes to talk about these things but in reality, we've only got two of them and we keep forgetting we have a hard time discussing this thing. So I'd rather just name them simply, some two names for what they are rather than than using the taxonomy but also, I have the proposal of like what if we just tracked as a KPI of the percentage of total MRs that come from the community over time and we would see that drop. I love that. Let's do that instead. Ok."
    },
    "t-NF5fNOyo8": {
        "category": "engineering",
        "captions": "Meeting Topic: Data Science\n\nRemy: I added a MR to the Test File Finder gem that the testing group created. It's to add a new option that takes in a specified custom mapping in a YAML file. So the idea is that we can use that to replace the tooling that we have. I have another work in progress MR to experiment with the new gem using the same mapping to detect the first test that we are finding right now.\n\nRemy: For the second MR, there's a lot of configuration that we need to do in the mapping and I'm not very sure how it's the best way to verify whether the mapping is correct or not. So what I did was create a small script to verify what is expected. Previously, we could do a unit test on it, but in this case, because it's extracted to a separate executable. So the next thing I tried was basically to test the executable. I'm open to any ideas on how we can improve this or how we can test it in a better way. \n\nRemy: One thing about the mapping is that we can also be more cautious, we can add more mapping and we can uncover more files. And if any of the test files don't exist, we will just ignore it.\n\nMark: That's very cool and that's great stuff. I will definitely take care; okay, great job picking that up and getting something together so quickly. Looking forward to seeing how this evolves. \n\nMeeting Topic: Engineering\n\nAlbert: As for me, I love road trips, and I did some road trips with one of my best friends a few years ago. We went to Canada in the Quebec part and we did, I don't know how many, but like four or five national parks. So hiking obviously, and also we went to see whales in the Saguenay River, between the river and the sea. So yeah, that's a really cool memory, and the next year we did another road trip with the same friend in Scotland, and that was also super fun. Road trips are always fun like this year as well, in Italy, that was awesome. But yeah, I did many road trips.\n\nMark: My most memorable would be India, so I spent two weeks in India. I think it was maybe about seven years ago now, but that was one of the first trips that I'd taken outside of Europe, and it was just amazing. It was just so different and experiencing that for the first time. But we traveled to maybe, I think, about six or seven different towns, traveling on the trains there because the trains in India are really cool. They've got different classes so you can sleep on there for the overnight trains or some of the short ones, there's not any beds. But we were on all sorts of different trains, and the trains themselves are a really cool experience. But we traveled down most of the west coast, and then back up again. It was only two weeks, but it felt really long, and we saw a lot of what they had in the south, including the backwaters, which is like lots of palm trees and lots of open water just set back from the coast. It's really beautiful. But that was especially memorable for me.\n\nAlbert: So like four years ago, my wife and I went to Japan, so that was very memorable because we went there for the Tokyo Marathon, and the Tokyo Marathon is known to be very difficult to get entry into. People need to apply and there will be a ballot to tell you whether you get an entry into the race or not. And we both tried on the first attempt and we got it. It was quite memorable. It was fun; there are friends who have tried three or four times and they couldn't get an entry at all. So yeah, it was fun, and also because there's a lot of training leading up to it so it makes the trip more worthwhile, I would say.\n\nMeeting Topic: CI/CD UX\n\nRemy: As for the insights, I sorted out the scoping of the priority and severity labels. It initially changed the default for the insights, the default labels, privacy, and civility labels. But then I noted that it would be a kind of a breaking change because users that do use the default charts would not see any data anymore if they don't change their labels. So, we decided not to change that for now and we can do that in probably a major version change if we wanted to. \n\nRemy: I added an MR to the Test File Finder gem that the testing group created. It's basically to add a new option that takes in a specified custom mapping in a YAML file. So the idea is that we can use that to replace the tooling that we have. I have another work in progress MR to experiment with the new gem using the same mapping to detect the first test that we are finding right now.\n\nRemy: For the second MR, there's a lot of configuration that we need to do in the mapping and I'm not very sure how it's the best way to verify whether the mapping is correct or not. So what I did was create a small script to verify what is expected. Previously, we could do a unit test on it, but in this case because it's extracted to a separate executable. So the next thing I tried was basically to test the executable. I'm open to any ideas on how we can improve this or how we can test it in a better way. \n\nRemy: One thing about the mapping is that we can also be more cautious, we can add more mapping and we can uncover more files. And if any of the test files don't exist, we will just ignore it.\n\nMark: That's very cool and that's great stuff. I will definitely take care; okay, great job picking that up and getting something together so quickly. Looking forward to seeing how this evolves. \n\n(End of relevant meeting text)"
    },
    "GgnkH3uih4o": {
        "category": "engineering",
        "captions": "I am the Executive Vice President of Engineering, and this is the September 22nd, 2020 Engineering Key Review. We are going to be covering four of the six engineering departments here - development, quality, security, UX support, and infrastructure. Development and Infrastructure have their own key reviews, so we'll try to direct comments to those meetings when appropriate. I know we had the infrastructure key review this morning, and there's one that was directed to this meeting about development. Note, I believe Christopher has a conflict about halfway through and has to leave early, so if we could put questions for Christopher's development team up as high as possible in the agenda, we get to those first. So maybe Christopher, do you want to elevate number six in the agenda up to number four? Sure thing.\n\nHere's a few items we need to discuss:\n- The largest contented pair marked as a KPI should be at the 75th percentile.\n- We are adding a Grafa A to the handbook under performance indicators. It should point to a page with five charts showing our progress.\n- We plan to pipe it into the data lake and get it to the 75th percentile.\n- We are moving towards centralized handbook-first engineering indicators.\n\nThis completes the overall view of development, quality, and UX. Craig, this is where you'll be passionate about the bugs because now you see the drill-down bugs all the way through. We're also factoring in security and infrastructure going forward.\n\nIt's amazing progress, I think we made you our data czar two or three weeks ago, and this is a huge increase in a huge volume of work that was delivered. The gearing ratio for our stats is at 38 out of our target of 42, and this makes our software robust for enterprise customers. We should look at creatively fixing this gearing ratio issue.\n\nIn the infrastructure meeting, it was discussed that gitlab.com site performance needs attention. Development on the front end, in particular, is working on it, mainly because the signals are coming from usability surveys showing Front End issues. We need to clarify the different performance initiatives and make them clearer.\n\nRegarding the bug metrics, we are moving to provide drill-downs before making adjustments. We aim to keep the metric at the target for average days to close severe bugs."
    }
}
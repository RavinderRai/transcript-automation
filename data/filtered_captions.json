{
    "rOqgRiNMVqg": "So it is the Security, Governance, Growth, and Data Science Meeting applied ML, ML Ops, and an anti-abuse team meeting. This is our meeting for September 14th or 15th in APAC.\n\nThe anti-abuse is moving product sections from security to data science. Data science is effectively a rename of the Model Ops section. Data science will include two stages: the existing Model Ops, which has three groups in it that one can talk more about, and the Anti-Abuse stage, which only currently has one group called Anti-Abuse. I think at some point there are plans to split Anti-Abuse into two groups, but that's not in the near future, and we're working through all the changes around that.\n\nRegarding the big rocks and hot issues section, we've implemented like a weekly refinement meeting kind of checking to make sure that stories are broken down tiny enough. I think with smaller bits of work, we're seeing a higher MR rate. It's debatable whether or not that's just inflated, right, like you can work on a small piece of code and ship it and you can do that a lot of times, you're going to get a higher MR rate. We're trying to be reasonable with that. I am noticing a nice tick up after implementing the refinement meeting, so let's hope for the best.\n\nA note on refinement in stack analysis: We're experimenting with a new section in our planning feature called 'looking forward,' and in there, we're using that as a baseline where we add issues that we think need refinement that will most likely be worked on in the next one to three milestones.\n\nOkay, after that, the all right bed ramp and the can't or won't fix security issues that way. Maybe we may be having there's the security issues that are subject to Fedramp. If you have a feature category that is dips compliant or certified, you're probably going to be part of the Fedramp evaluation. And any security issue that has a CVE associated with it, which means dependency or container scanning specifically has to have a remediation plan even if they're false positives. So that's led to a separate discussion on what do we need to do? Do we need to do anything related to security findings on the commercial versions of the analyzer specifically.\n\nWith recent changes, we've done a couple different changes with the secure and governance 'brokair' from secure and our DataOps Team. I just compared it to the name of my team with my peers, my peers have one-word team names Ops, Dev, Create, etc. Mine is SEC, Growth, and Data Science, which is pretty wordy and also makes it like when I go into dashboards I have to pull data from multiple places across my teams so I was thinking about one-word name. I've started to get feedback on it, naming things is really important at Gitlab, to name the right kinds of things and give them good names so I'm going to run it by David DeSanto tomorrow and he's a great person to bounce such things off of.\n\nThat's actually my intent is it only affects my stuff not everyone else's but at least everyone else is in a small way or others in a small way but we'll see. Any thoughts on this? Good idea, bad idea? I'm not wed to this, I'm looking for feedback. Obviously, the other examples related to either sections or stages whereas the 'enrichment' doesn't so you'd be introducing something new here. This affects me as well I have a subset of 'enrichment' so it would be kind of enrichment light. I'm not sure where I think you and I've spoken about this I'm not sure we get approval to introduce a new name or Department level we'd certainly have to talk to people Ops about introducing that in Workday.\n\nA couple of things, you know these kinds of things I would sometimes put in Slack but I'm trying to avoid a number of distinct Slack messages so putting it in here making a lot read-only when possible. So I've got C though which is not read-only, sorry I would like to add announcements of work anniversaries and new hires to the meeting template. PM does this, I attended the PM staff meeting, I was a guest speaker there this week and I liked the camaraderie we have, good camaraderie. The camaraderie there was pretty good. Fer, who's shadowing me today, I think he sat in on the PM meeting as well. It has a pretty good feel of just people really knowing each other well and getting along well. So those are just two things I took away from it is work anniversaries and new hires. Oh, verbalizing Thiago's comment, let's go here; yeah great idea for new hires, don't care much about work anniversaries we already have tools for that. What I'd say is I always seem to miss announcements as they cover the whole company versus about just announcing for our team if interest in that part I'm happy to exclude.\n\nThomas looks like you had Thomas and Mo you had some thoughts on this too. Yeah, I like it, we don't celebrate enough. We don't do enough for team cohesion, team celebration. Across the board and just as a corollary related thing that I haven't communicated well I was hoping to add this kind of thing to our monthly section-wide retrospectives new hires, discretionary bonuses, work anniversaries, big feature releases. I mean anything that we want to announce and celebrate we ought to make sure that it's. I don't want to say shout to the rooftops but we're shutting to the heavens that they're big deals and we don't make it and ourselves in my opinion.",
    "Tmd5eKVgySY": "- Obviously, I couldn't open right, so it's the SEC Growth Data Science staff meeting which we just discussed a confidential topic and now we're going to discuss the non-confidential things.\n- Yeah, just a bit of news about new hires. The compliance group has a senior frontend engineer joining on November 28th so that's our once initially based out of New Zealand as well.\n- We've got a four-year work anniversary and a three-year work anniversary, one for first versionertino that to garage so they put up with us for a long time so this is always worth celebrating so I'm glad they're here so we'll consider to the meeting.\n- So Best in Class BI also known as bicokrs for securing Governor being finalized for Q4 byproduct management with a ETF Distribution them by the end of this week.\n- Once they are please be sure to engage on them ASAP as we want to accomplish the ones slated 4p4 in Q4 wherever feasible.\n- If it would help we can consider changing team priorities of the teams working on the okr's and those not to help out.\n- Please also continue to give PM feedback and ask questions about the okr's and the associated epics and issues to make sure we understand the goals and ways to deliver them as iteratively and effectively as possible.\n- We're talking with our product managers what work have you got coming up for us in Q4 that you've already prioritized that relates to Best in Class.\n- the thing from PM is the best in class so cares are likely going to be the work already on the backlog a subset of the work already in the backlog that we're already working on or planning to over the next two or more releases.\n- Once they're announced which is why I'm bringing up here any questions or comments about that so that the TLDR here is we're talking with our product managers what work have you got coming up for us in Q4 that you've already prioritized that relates to Best in Class yes great and then then we need to choose between those and other things we should choose those it's you know it's very very generic you know guidance of course but we don't know the details yet so it has to be generic.\n- If you haven't already done so please add a comment on good bad and try on your Q3 OKR since we're two weeks into Q4 and tag your manager for review and then close them sometime next week or so would be great.\n- I'll go next it's hard to follow that up with metrics but I'm going to try anyway so I was talking with Derek earlier this week and he's part of a working group for devsecops adoption and we've historically within SEC so secure and Governor we've had a challenge with metrics and accurate metrics collection.\n- I have a one from the Earth who's working tightly on that and I'll ask them whether they're willing to look at the section lead and get back to you.\n- I opened up a team or a issue for planning our sex section team day still trying to figure out what the date should be but we're thinking early in December.\n- The first question is would anyone like to co-host or collaborate with me on finding this out and the second question is going to be around in the past attendance has been fairly low so just brainstorming ideas on how we could improve attendance there and could be carried out ASAP as well.",
    "JwBNYjaEwmQ": "This is the SEC growth science data science staff meeting for January 18th. Let's jump over to the tomorrow, it looks like you're the next item. I just wanted to give a huge shout out to Lucas and James for receiving the discretionary bonus on their efforts on a recent customer escalation. A link to personal access tokens will now be automatically revoked for all GitLab team members. Please review draft Q10 OKRs for Secure, gather, govern, growth, and data science and start working on OKRs for your teams. Continuous vulnerability scanning capabilities and dependency scanning are important goals. Career growth of team members, team member training, and 360 feedback cycle are crucial. Finish the Gap analysis and delivery of short-term wins for secure, govern, growth, and data science. Application health error budgets and continue to burn down the list of customer impacting bugs. Move subset of secure features to open-core for community contributions. Consider switching responsibilities onto the ultimate license for core members. Explore opportunities for contribution through issues and migration initiatives. Open-sourcing security features from premium tiers is important for community engagement. Thank you for your participation and have a great day.",
    "Y33pKPUamCQ": "The text after removing small talk:\n\nDirectly hey the recording cool is so I know that you have had some discussions on the last session which I didn't attend due to my day off about the capacity for the UX research and communicating that to the PM's. So curious, will you guys move this topic to this session? What were some of the outcomes? Where did you finish? You know what was discussed? Basically, there was a pretty long discussion. I mean, I liked multiple views, and there are different perspectives on how we should manage this, so I don't think we reached a concrete conclusion. Besides, yes, we need to communicate our capacity to our PM's, and we need to find a good way to do that. I don't think we reached a very concrete conclusion, and I think there were still thoughts regarding these. So that's why we moved it here.\n\nI was just having a discussion with tau and both engineering managers of taxis about basically creating more visibility and what is being done for a milestone. And then we eventually got to the point where there was a little section in the issue she was. She's thinking of creating that displays, you know, design priorities or design responsibilities. And what I said to her back was like, \"Hey, we need to make sure that we are not, you know, putting the design responsibilities within a time box of a milestone because that doesn't fit in there. Some design efforts might fit into weeks while others fit into one and a half a month. And with that, we got to the discussion back to like a discussion-based style of working. And that kind of falls in line with the validation tracking board, which had been discussed in the few UX weekly once upon a time; and like a few weeks ago. I was if others already apply this. So the idea is that you have your columns of problem validation, you got your design workflow, design workflow solution validation. And instead of filtering down for a milestone, we filter down to, you know, your assignee and...\n\n...continuous integration and the author, me, Demetria. And I see, you know, my issues within those columns. And if one moves to the next, or one moves to planning breakdown or scheduling, whatever it means that a spot has opened up to some extent. That is a simplified way of looking at it because we don't individually weight issues, and I'd say our process and this will be different than engineering but it's kind of visualizes it a way, you know, \"Hey, what is the weight or what is the current effort of design at this very moment? And if something changes, let's review this, for example weekly, and say, \"Hey, there did things change versus last week, hey, something did change. The spot opened up. Does this mean you can add a new issue?\" But if so, then let's already do that, you know, work ahead. And that is the idea. We took...\n\n...a little bit of a different approach, we have a very similar like Kaaba setup, where there's validation, the design phase of validation, and working backward. We try to coordinate and make sure that every milestone has some sort of research effort happening. And the kind of look at the board and communicate about where we should focus. It tends to be, \"Here's a bunch of stuff,\" and then, \"This is the time slot. We'll add here.\" And I just kind of have a commitment of making sure each thing can kind of be done in a time range. And it flexes in weight. So I try to keep it in two milestones, but I try to reflect it like a solution validation as a research effort. So it takes a little longer than maybe the actual design phase might. So I'll try to pair and prep for the solution validation in the next one. So I think I managed my own time and report it back to Tim. I think that's the way I would explain it. So it's a lot more. I kind of just jump in and say, \"This is the research that we're doing based on what's in design and solution validation right now. I'm sorry, I tried to make sure there's just one research effort happening in a milestone. The backlog is usually emptier on my side than it is on Tim's just because it goes through the cycle so quickly once it hits design and the solution validation, we're working on figuring that out. One of the things we're going to do to try to do that is 12.7, I'm going to do product validation and let him have an extra milestone...\n\n...to get things through problem validation, so that means that Tim does all the problem validation, and you specified or, you know, do the solution validation, let's the weight as album validation is Tim's responsibility, he's the DRI in for solution validation. I'm the DRA, but we try to partner and make sure that our research efforts are aligned and I get involved in problem validation so I can understand it and gather the information I need. And he sees solution validation it goes through, so it's a partnership but we have a DRA for each side. So in that way, he with that contributing to the UX research insights repository from the research that he does, Board that you partner, he better be but symmetry those. That's a great point. I actually just discussed this with somebody else, the research team I need to go back to all of our product managers and make sure they understand what the process is. I don't think they do, but they will be required to write those insights just like we all are writing those insights to put them in the repo. Otherwise, the research that they do, it's not usable by anybody else for themselves, and that kind of sucks...\n\n...and that includes not just the problem validation. Any customer interaction that they have they should be documenting what they learned and in the repo. So good question. So the answer from what we've been doing, the meat tree is he actually ran the problem validation sessions and recorded them all. And then, I synthesized them. And that's how we partnered on it. So that we were both able to speak to it, so we were both involved in creating the insights. I think moving forward where we might have a discussion because the insights can take a while of splitting that effort a little bit more. So as the DRI, he would be the person doing those insights and when it's me, it's my insights. We're still work in progress. New team and all that. And it's a new insight process too. Like I've never done it this way either I've just been writing like 45-page PowerPoint reports, other places I've been, and you know if we don't break him down and put him in the repo, what will happen is what happened to me the other day. \"Hey, does anybody know if we ever did any research on XYZ? I don't know. Have you checked the repo?\" Because what happened to me in the past is I have to go through all my old reports and see if we didn't do research on XYZ...\n\n...and what did we learn so the repos would post to be able self-service for the insights, but we have to continue to feed the repo like \"What are your experiences there with what and the way you do research before I think for us it's not much different than anything else in the sense that we kind of talk about everything that needs to be accomplished. And we're also moving into the Kaaba style of world, which will give us a new board planning board where most of this activity can happen and we can track it there. Currently, it is happening on the mouse and boards, which is a little confusing because it really has nothing to do with the milestone. That's more focused on upcoming milestones. But really, I mean, we just kind of talked about what we need to accomplish from design for a research side in development side. It's all kind of just a continuous conversation because obviously the more research we do, I mean, less Lori is available to help us out like the more research we do...\n\n...the less design we do. So it's all kind of a moving target of what we need to accomplish and when we want to accomplish it. Ice it sounds like everyone is figuring out the way to do it. Yeah, I kind of like, like the way of like just like setting an average, we pick one research topic per milestone. I think that's kind of this is the maximum. I feel like we can do without all of the work design more than we need to be done and that's kind of like sets these expectations and we also have to be planning for that we have been earlier with War II and I forgot which PM hostage Tau. This Tau Tau yeah thanks I had so much courses all today. Discussing that. It's nice to plan all those things a bit earlier like you know kind of like \"Okay what are those things are we going to be looking into one or two milestones. Just to give everyone a heads up, because I think the APM should be able to do that plan for that it's one of the things that Tim and I have been trying to focus on is we try to partner with Loree and we have a goal that Lori knows it's not only what research we're doing right now what research we want to do next one. But at least the general thoughts of three milestones out, fully recognizing that that's a long period of time, and things change, but we try to make sure that Tim and I are on the same page in terms of what we want and... \n\n...our moment of truth, if you will, is when we kind of lift rope, there we go Laurie into the conversation and make sure that she's on the same page with us. It's kind of helps all of us because the it is kind of helps all of us because the, you can say this is a real easy initiative maybe it needs less time and we can work it here or this is a big one like you're going to need to stretch here before we're in the milestone where it starts a question like this is super interesting because I saw that and maybe I would like you to have a look into this issue later and I want to have a team go and look there as well because so I made this like a graph model-like illustration where I'm trying to visualize the timelines for their research to be done like kind of like to get on the same page, because I feel like we're talking a lot about the timelines within the stages. And there was some feedback that they had said the discovery stage. I suggested that can happen three two milestones I had or two. I don't remember and that sounded too much for people and there were a few comments that if we do or like if you plan a research to three milestones ahead doesn't it become obsolete until the actual development time will come like what's your experience there? Yeah, and that was something I wasn't sure if that was me or not. I didn't want to step on any toes. I think as long as Tim and I have very clear communication and conversation about if things are flexing and changing and it's also we have the belief that the more research we do upfront, the faster everything else is going to go for us and the more likely it is to be successful. I can speak to that now...\n\n...the solution validation we're doing because we did such thorough problem validation. I've been getting consistent like this is exactly what we wanted this is what we needed and every designer loves that moment when it happens. And so because we have that and we try to make sure the research is big enough that it could be a couple milestones of work so we were doing additional GitLab metadata and it took me a milestone to put the design together and test it and sorry and also test it. But there's three or four milestones of engineering work that will go behind those changes. So we've been trying to pull the levers of scale of the research and understanding and those kinds of things to try to get that as far out so that it is workable right. So we don't have engineers that just have nothing to do which is where I think... Really want to recognize that that is most appreciative thanks a lot.\n\nThe text about the EBI e UI app ik does not pertain to the three main topics so it has been excluded from the summary.",
    "kGHyK_SkZB0": "So, my item, there is pretty big and rather radical change from the cicd private catalog. So, we discussed this a lot, and this came up and inspired me a lot while I did the journey map exercise. I didn't feel it's right to having this private cicd catalog scope here. Namespace because we have interviewed several self-management customers. It could be really multiple namespaces, I'm not going to disclose the exact number, but it could be a lot, of course, it depends on the organization size. And how Dove announced this change and this will impact a bit of our product roadmap or the timeline. Design-wise, the impact is not that big but I think this is the right way to go, so I was really supportive about this change and yeah, you can see that now we simplify the structure. So, we will have one organization catalog and one open-source catalog that is kind of similar to The Marketplace. And I have personal updates so you can read through it.\n\nYes. So, I am just analyzing all the sessions from how do we use AI to help users optimize their Runner and CI builds. And it was pretty cool, we used like a decision tree process from this book on AI that I'm reading, and basically the idea is if you can put the decisions into clear if statements then you have support that you can automate this workflow a bit. So, we didn't know if it would be like I think about this but that's related to this and this is really but actually it's pretty straightforward. Anyway, so I won't go into the results, but I'm working on the report and that'll come out. I think I'll share it with the uxr team soon and then it will come out next week. But there's really good information in there about just the details that people need to make decisions. And kind of the outcomes for optimizing Pipelines and the process is very trial and error and set it and forget it. That's the main thing, so I think that's like one of our CI learnings.\n\nYeah, could you just elaborate a little bit more on the effort? Yeah, so I'm actually very proud of us as a product company that we're like ready to move into this space. So, we're looking at kind of the connection points between git lab and the cloud and like where the workflow lengths are kind of the tools that users are using and that'll inform part. Some integrations that we're building like soon with gcp but then also long term what works well in terms of the integrating that does it and that's actually where I think we can bring in some questions about like resources and whether or not they should live at the project or the group level. Like how teams access secrets for example like where do those get stored in git lab and is it like higher up organization level? Because I'm thinking a lot about this new change that's coming related to organizations with some new nodes because that's like the new play with the catalog which I think is really smart which is to put it up there but then I'm wondering like what else could we move up there? Like maybe the secrets because they're organized at this company level but that's what we can look into talking about.\n\nLike can you later go and chime into the issue that I have created for navigation and share your views there, because yeah we don't want even though I have mentioned about like taking it out of cicd if there's any research that points at we should have it maybe as a part of my navigation or at a higher level in navigation, we should be aware of that and that would help us inform the methodologies that we would like select for research.",
    "HFEFQ4NcgSQ": "The Pipeline Authoring team is working on improving collaboration between UX, PM, and Engineering. Engineers provided detailed feedback on collaborating with UX, highlighting gaps in communication. The team realized the need to include engineers earlier in the process to establish trust and improve shared understanding. They are focusing on fostering async communication to document better and create a more accessible information flow.\n\nIn the CI team, discussions are productive, and the engineers are responsive to updates. The team is focusing on continuous improvement, with a designer implementing Loom videos for better communication of design vision. Feedback is crucial, and the team is looking for ways to improve processes and collaboration.\n\nRetrospectives are important for teams to review action items and make improvements. Each team handles retrospectives differently but aims to address critical points and create actionable items for future milestones. Transition and team changes are inevitable, and support is offered to help team members during these times.\n\nThe discussion also touches on conference experiences and plans for personal development on Focus Fridays. Collaboration and sharing tips for interview training and shadowing experiences are encouraged to enhance team learning and growth. The importance of aligning priorities and checking in regularly with team processes is highlighted. The focus is on continuous improvement and effective communication within the team.",
    "qGFoZ8yodc4": "Hi, this is Eric. So, it's February 18, 2021, and this is the Engineering Key Review at GitLab. I've got number four in the agenda, which is a proposal to break up this meeting into four departments' key reviews. Currently, Engineering Development, Quality, Security, UX, Infrastructure, and Support do their own key reviews already. I have the reasons why: increased visibility to go deeper, increase the objectivity with which my reports can manage their groups, allow me more time to focus on new markets, and allow me to shift into more of a question-asker mode than generating content and answering questions in these meetings. But to avoid adding three extra new meetings to stakeholders' calendars, I propose we do a sort of two-month rotation. So, month one, Development, Quality, Month two, Security and UX. How do people feel about that proposal? I think, in the group conversations, it's working really well. So, I'm supportive, and this is the smallest thing. Maybe we need four meetings a month \u2013 it's the biggest department; it's super essential. But you proposed this. I don't, I could see either way. So let's stick with the proposal. Cool, we'll try it, and we can be flexible. I mean, the development is larger, maybe they go more frequently or something like that. But we'll see how it goes.\n\nAnd then number five, which is, we've got R&D Overall MR Rate, and we also have R&D Wider MR rate, both as top-level KPIs for engineering. The difference between them in the simplest sense is that R&D Wider MR rate includes both community contributions and community MRs. The problems I see with this are that one, the Wider MR Rate, the one that includes internal and external MRs, it duplicates the Overall MR rate, which is, sorry, sorry. The Wider MR rate should just be external, right, and the overall should be narrower plus wider. Oh yeah, like we say the wider community, right? Right. Okay. So, I'll have to check the taxonomy, Lilly, can you confirm, sorry, that's Sid's reasoning, is my understanding as well? Yeah, I believe wider MR rate just captures community contributions only and the reason we measure that is that one of the most likely failure modes is that we lose the community. Yeah. \n\nSo, Eric, where it gets goofy is that when you look at a specific team within the company, there could be contributions outside of that that aren't community contributions. They would be viewed community contributions by that group but effectively they're not from outside the company. So that's why we use wider to kind of reflect that, and narrowing is very specific to the team. Are you saying that if someone in plan contributes to verify, it's viewed as wider, not quite that, verify is just fine. It's when you look at like the development versus infrastructure. Infrastructure will oftentimes contribute to developments work, but it won't be counted as MRs. Okay, that's a potential bit of fuzziness that we should talk about separately. I didn't have that in my sort of critique of this, but that doesn't necessarily make intuitive sense to me.\n\nSo part of my critique of this can be thrown out because it's not as duplicative as I thought, but I still think there's a problem with R&D Wider MR Rate, which is this thing doesn't really move in part because it's a rate, so it feels like the way to drive this up is to specifically drive community authors to contribute more than one MR per month. That's how this moves up because it's a productivity rate like we use internally, and that doesn't necessarily feel like the right thing because there are scenarios in which this goes up, we've actually got fewer contributions overall and fewer contributors overall.\n\nWait, hold a second. So you're saying that R&D Wider MR Rate is the number of MRs per external contributor. Oh my goodness, that should not be the thing. It should be contributions per GitLab team member. So the country, those, the thing above the division is the external ones, the thing below is the number of team members at GitLab. Is that the case, Lilly? I'm checking right now. I think, so, internal team members, so unless we start calling people outside the company team members, then it shouldn't be done. Yeah, just clarifying here. So, our numerator is community contributions, and the denominator is GitLab team members. So it's not per external member. So what we're doing there, Eric, we're not trying to say how many MRs does someone send if they send something. We're saying how many MRs from external do we get for the size of our organization?\n\nSorry, I have a childhood emergency outside the door. So maybe explaining the context behind this. The context is, as we grow as a company, we should make sure we keep the community up. Like the logical thing is for the community to flatline and the size of the orc to go, and before you know it, you've kind of outgrown the wider community. Yeah, what I'm seeing is we created this presophisticated taxonomy with prefixes and postfixes to talk about these things, but in reality, we've only got two of them, and we keep forgetting. We have a hard time discussing this thing. So I'd rather just name them simply, say, two names for what they are rather than using the taxonomy but also, if I have the proposal of, like, what if we just tracked as a KPI of the percentage of total MRs that come from the community over time, and we would see that drop. I love that. I love that, let's do that instead. Okay, but the thing, why we have this complex thing is because you can gain that. You want to game that; you want to game that, you just produce fewer MRs with the engineers at GitLab. So if you drive that really hard and say this is your number one goal, it's very easy to achieve, you just tell all your engineers to produce half. So we have different metrics to prevent that from happening the same way that like Support, SLAs, and Sac kind of buttress one another. I think we're robust to that. But simplifying this would make these conversation go much, if you as our CTO don't understand them, we went overboard. So I'm supportive, you understand them. And I forgot, and I was reviewing this stuff this morning, I'm like, there's a problem with this, and you just reminded me of the context. So, yeah, if I can't hold up my head, the percentage that comes from the community, I love that, it's what all our investors ask about. Let's do that. Okay, cool. So, Lily, if you can work with Max to make that transition, that would be great. And I'll bowl the one that we're talking about at the Roman, numeral 3. Thanks. I'm off the call; sorry it was a bit late. Timeliness. We do have PIs on the raw number of community MRs, and we can make the shift and why they're confirming from the definition, I think that only counts for community, and that's what the definition is. Cool. \n\nAlright, number six, the Christopher. Sorry, I was looking up to see if I had the percentage graph because I think we played around with this at one point and had a draft of that probably about five months back if I can remember, Lilly. Just FYI, in the month of February, if you're looking at any particular metrics, particularly in development, MRs, we haven't had updates in four days. There's apparently a lag issue that has been problematic for the data team to get updated metrics, and they're working on that. Okay, I'm sorry, Mike, you got the next one. So yeah, I think there's a lag, later on, we continue. Sorry, I said FYI. \n\nIn addition to the KPI status, I just wanted to touch on the Postgres replication issue there real quick. I've been trying to get my arms wrapped around it. Do we have the right attention to this? This is kind of Eric. I don't know if you were committing to hitting it towards this in the last meeting around some of the infrastructure improvements on the product side. I'm just not quite sure whose responsibility it is to focus on getting a handle on some of the constraints we have in replication. Yeah, what I was mentioning in the product key review about an hour ago I think is sort of unrelated, and so I think the driver needs to be your kind of data engineering team, but of course, there's a dependency on infrastructure because that's where the data is being piped from. \n\nThey do own that data source, yeah. I'll say for the replication lag on that slave host, where, so I'm sorry, not the one, the secondary host where the data is being pulled from, like the infrastructure would be the drive for that, and any escalations, but I'll own those. And I know we have action plan for that as far as creating another dedicated host just for the data team to pull from. Okay, I did actually, I saw that issue, and I did talk to Craig Gomez a little bit as well, on the database side, just to see if there's some database improvements, and I'm still trying to figure out, you know, if it's truly just a dedicated computational sort of resource, a server, or if there's actually some database tuning that needs to occur. \n\nDo you have a sense of that? There's so, I'd say it's three different things. It's having a dedicated host that doesn't have conflicting query traffic coming from other workloads. There are some tuning performance or tuning improvements to be made, and then there's also improvements in, and this is where it does maybe relate a little bit to what the topic was in the last review. Basically, the overall demand on the database layer from communications and improving those. It's definitely not just one of those things, but one of the most specific actions we're going to take though is separating out and having a dedicated house so that we're just dealing with the profile of the data engineering traffic on there and not having conflicting queries affect the ability to update the replication. \n\nSteve, I definitely want to partner with you on this one because I don't know if the demand on those databases is only going to increase, it's not going down, so I think we need to get...I'm still unclear on where to focus on to get the biggest bang for the buck. I think if the computational resource dedication, that's going to be a good thing, but it'll probably going to squeeze the balloon, and the next area will unearthing itself. Okay, and I'll tell you what, I'll put it to the infrastructure review for next week. Okay. And an update on this issue. Thank you, Steve. So, coming back to seven or yes, thank you, and Rob was in the assassination incident this morning as well. Ryan just said we have the attention there. \n\nJust provide an update on previous conversations, we're continuing to improve defect tracking against SLOs. There is a first iteration PI that we are experimenting to show a percentage of defects meeting the SLOs key findings. As one's are hovering at 80 percent, S2 at 60, we've been mostly focused on S1s and S2s at this point, hence why S3 and S4 are lower, and this will likely be the case. \n\nWe're also in point B, we are working on the measurement for the average, open box age. This would give us a whole picture of what's left if,... if the age goes up or down, would..., as you're clearing the backlog, the average age should go down as well. There's one PI yet, but I just wanted to update and ensure that we're on this. It's not off track. Number C, Craig, on S2, yeah, I was looking through the charts, and I noted that there was a spike in meantime to close. Yeah, and just wanted to see if you had any insight into that for us. This is about the S2s, the S1 looked fine. \n\nYeah, this is where the point be on supplemental shards in the backend helps. So I haven't seen a dip in age or the count overall. I think it's the latter; we need to dig deeper into that, and also the data lag. I would like to reevaluate once we have the whole picture when everything's synced in as well. Christy, do you have some insights? Yeah, I'm just wondering if part of this could be the fact that we changed the severity across the board for MRs to S2, and so we may have some older bugs in there that hadn't been addressed because they were at a lower severity. Now we've moved them to S2, and maybe that caused a little spike. That could be the case. If we did limited fashion, it won't be a huge volume; we also iterated after that to P0 through P9 priority since Product prioritization so it wouldn't account entirely to that. This isn't the point of a key review, but I know that they've got backed up on those issues so if some good portion of those are in or created or related, the... that might be lifting it as well. I can take the deeper digging and provide an update next time. \n\nI think we need extra debug slicing the data here. So you would like to go to 0.8. Yeah, we are now measuring S1 S2 SLO achievement with closed bugs but if you look at the number of bugs it's exponential growth, and it would be trivial to achieve 100 SLO achievement if you just look at closed bugs even though if there would be a major problem in the company, 99 of all bugs are overdue. As long as I only close ones that are still within the SLO, I'd have great achievement. So, I think we shouldn't be looking at the closed bugs. I think we should be looking at open bugs, the entire population or percentage of those within the SLA time. I think we're doing it the wrong way. Thanks for the feedback. Said, hence why we wanted to have the average age to measure what's outside in the open. We can make this iteration to measure, also measure, focus on the age of all opened bugs, including open bugs. This average age would get closer to it. It's not what I'm proposing. What I'm proposing is of the open box or percentages outside of SLO. So display it as a percentage; you only got to do it for about the open box, not the closed one.\n\nGot it. The exceeding SLO for open box or open bugs that are within SLO, so you have a chart that should go up and to the right like everything else sounds great. We can take it to the next data metrics work stream to deliver this. Cool, thanks. These are pretty much a little tricky Mac; you'll have to figure out how to be able to have charts that we can historically reconstruct if we need to. So when tickets close out, you need to go through their history to figure out at this time when it was open, did it breach the SL, or not. That's a good point. This might be much harder computationally and so I totally respect if we can do it for that reason. \n\nCool, I see, Craig, I just wanted to ask the team like if we went through all the key meeting metrics everything looked inline with prior periods and looked good. Is there anything the team wants to call out especially that we should be watching? Yeah. I'll call out, the good news is in Q4, we had our smallest decline over several quarters. So we only went down by 0.1. The quarter previous was 0.6 or six tenths of a point, and the quarter before that was a full point. So we see this as an improvement even though it was still a decline, but it's still a decline. Obviously, we want this actually tracking in an upward direction. We also don't have enough data to know whether or not this is an actual real trend. I'm optimistic, I think this is a good thing. We have had a much keener focus on SUS over the past several quarters. So that's why I think okay the work that we've done I think is catching up and getting noticed in SUS. But we got to keep an eye on it. We can't assume that. That's the case. \n\nAnd the bug discussion above points out that, we have an underlying problem right now in our metrics measurement. So, if we change the measurement to reflect, then hopefully we are in good shape. If we don't, and we just flatline and address it so that we flatline, open S1s and S2s, you'll see a temporary jump up, and us above SLOs as we clear out that backlog over that period of time. And I have a point C, which is similar to infrastructure; we need to get more security work prioritized. We're hearing that from the team but either that problem or that activity is sort of currently reflected in our security metrics, so we have some work to do long term to make sure that we see things like that in the metrics and the measurements that we're making. \n\nBack to you, Sid. Yeah, the RMR rate seems significantly below target, and maybe I hope that it would bounce back from December. I think it bounced back, but not back on target. Any context there? What's going on? So, with family and friends days, we actually had some heavier vacation days in January than we historically have. One thing to note is that we are actually at a higher MR rate, if you look at the last 18 months, we're actually at a higher year MR rate than we were back in each month this year. \n\nSo, if you compare October to November, December, and January comparatively to last year, what you'll find is we're between a half point and a point five MR rate above where we were in the month of the previous year. That's great context, thank you, Christopher\u2014good work. Yeah, so the expectation is that February is a short month; we were at, I think, 16 workdays with friends and family day and other things. Usually, we see a little bit higher activity during release week, so that's not accounted for yet. I was hoping to see a better result right now, but with four or five days particularly around release week, that's when we usually see a little bit higher activity. \n\nSo, that's not accounted for yet, but you know, March's merch is when I'm expecting kind of see a real rebound, much like we did last year. Awesome, thanks, the other context I'll give is we now do time series targets. So when we change the target, you'll see it reflected in the line, so if we were to look back historically here, the goal here was actually lower and Christophers was ambitious, and we kept raising, and we kept meeting that, so it should step up here and we could go back and reconstruct that if we really wanted to. And the origin of the kind of the seasonal dip here we raised it to I think 11. We realized we were kind of hitting that point of diminishing returns and the right thing to do business-wise,",
    "t-NF5fNOyo8": "# Engineering Topic\nI see Mark's in the doc. I'm sure he'll join here soon. In the spirit of Remy coming back, I thought it would be fun to talk about a memorable trip or vacation people have taken. Mine, I think I will remember this for quite some time. In March when I went to Aruba with my wife, it was right as the pandemic was starting, and we kind of were waffling about going. It was great. Aruba is like an island in the Caribbean, so beaches, sun, things that we don't get to experience around here. Super fun. But, as we came back, that was when everything was shutting down in the US, and that's pretty much our only memory of the trip. We came back, and the pandemic was unfolding in the US. I was talking with my wife about that this weekend, how it's kind of soured the trip. But it was fun when we were there, but it'll be memorable for a different reason. Remy, what about you?\n\n# Data Science Topic\nAbout me? So, I love road trips, and I did some road trips with one of my best friends a few years ago. We went to Canada, in the Quebec part of Canada, and we did, I don't know how many, but like four or five national parks. So hiking, obviously, and also we went to see whales in the Saguenay River, basically just between the river and the sea. Yeah, that's a really cool memory. And the next year, we did another road trip with the same friend in Scotland, and that was also super fun. So, yeah, road trips are always fun. Like this year as well, in Italy, that was awesome. But yeah, I did many road trips, so I wouldn't go to details for each one. Mark, what about you?\n\n# CI/CD UX Topic\nMy most memorable would be India. So I spent two weeks in India, I think it was maybe about seven years ago now, but that was one of the first trips that I'd taken outside of Europe, and it was just amazing. It was just so different, and experiencing that for the first time. But we traveled to maybe, I think, about six or seven different towns, traveling on the trains there, because the trains in India are really cool. They've got different classes, so you can sleep on there for overnight trains or some of the short ones. There are not any beds, but we were on all sorts of different trains, and the trains themselves are really, really cool experience. But we traveled down most of the west coast and then back up again. But it was only two weeks, but it felt really, really long, and we saw a lot of what they had in the south, including the backwaters, which is just lots of palm trees and lots of open water just set back...",
    "GgnkH3uih4o": "Hello, I'm the Executive Vice President of Engineering, and this is the September 22nd, 2020 Engineering Key Review. So we're going to be covering four of the six engineering departments here; Development, Quality, Security, and UX support. I know we had the Infrastructure key review this morning and there's one that was directed to this meeting about development. Note: I believe Christopher has a conflict about halfway through and has to leave early. So if we could put questions for Christopher and development up as high as possible on the agenda, we can get to those first. Maybe Christopher, do you want to elevate Number six in the agenda up to Number four? Sure thing. So uh, there was a request that we have the largest contentful paint marked as a KPI at the 75th percentile. Right now, what we've done in the short term for the first iteration is we are getting this in Grafana, so we've added it to the handbook under performance indicator. It actually will point to a page with five charts of the different pieces that we're looking at improving. Right now, it shows the median; we'll need to change that to the 75th percentile. So our plans are to pipe it into the data lake and once it's there, get to the 75th percentile and then break it out into the five PIs. Which one we'll need to select as the KPI for that.\n\nMax, you've got number five; sure, thank you. So as a follow-up from the last meeting on me being the single interface for engineering metrics and how we remodel how we do data projects. Here's the FYI on the current process. Some special thanks to Kyle, the lead CAD, and the data team. So, five new PIs on personnel staff, the gearing ratio for quality and UX, six new PIs for overall community contributions. The first of them being key, which is the volume of community Mars, and then we cleaned up roughly 51 APIs to have clear directional indicators."
}